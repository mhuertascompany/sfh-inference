{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b865f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "#  Important !!!! path to shared tensorflow dataset\n",
    "#data_dir='/storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle'\n",
    "\n",
    "data_dir ='/scratch/mhuertas/tensorflow_datasets/eagle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265a5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfh.datasets.eagle import eagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b650134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /scratch/mhuertas/tensorflow_datasets/eagle/eagle/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3561372f6c44ce9b8293b0983c2ff83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4070f9f4ec0d46fc970331799d42a7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f96d48bb26b404b888f8103a72d0098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /scratch/mhuertas/tensorflow_datasets/eagle/eagle/3.0.0.incompleteNQVH9K/eagle-train.tfrecord*...:  â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset eagle downloaded and prepared to /scratch/mhuertas/tensorflow_datasets/eagle/eagle/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:30:37.584601: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dset = tfds.load('eagle', split='train', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d864b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22  20  93 105  91  23  21 106  92 130 107  24 131 108 132  81  71  90\n",
      "  79  45 109  82 133 117 110   3   8   7  84 134  80  68 118  76  85 111\n",
      "  13  61  42 112 119 135  83  88  94  19 113 120 136  63  70  44  87 121\n",
      "  15  18  12  10  78  34  69  62 114  86  43 122  14  11  77 137 115 123\n",
      "   9  65 129  46  72  35 124  89 138  17 116  64  99  16  98 128  52 100\n",
      "  56  36 101  53   1 102 126  96  54 103  37 104  50  57 125  95   0  51\n",
      "  38  97  33   2  55 127  39 139   4  40  25   5  41  26 140   6  27  28\n",
      "  30 141 142  31  48  32  60  49  29  58  47  59  73  74  66  75  67]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Reordering the wavelenghts\n",
    "#wl = np.loadtxt('/storage/scratch/mhuertas/data/sfh/tensorflow_datasets/tng100/downloads/manual/wl.csv')\n",
    "wl = np.loadtxt('/scratch/mhuertas/tensorflow_datasets/eagle/downloads/manual/wl.csv')\n",
    "inds = np.argsort(wl)\n",
    "print(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcbfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Keras model implementing PixelCNN.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "import time\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfkl=keras.layers\n",
    "\n",
    "def generate_model(n_timesteps, n_filters, *, n_channels=1, n_components=2, kernel_size=3,\n",
    "                   n_dilations=5, list_of_dilation_rates=None,\n",
    "                   list_of_filters=None):\n",
    "    \"\"\"Generate the PixelCNN Keras model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_timesteps : int\n",
    "        Number of time steps.\n",
    "    n_filters : int\n",
    "        Number of filters.\n",
    "    n_channels : int, default 1\n",
    "        Number of channels in the dataset\n",
    "    n_components : int, default 2\n",
    "        Number of components in the Gaussian mixture distribution.\n",
    "    kernel_size : int, default 3\n",
    "        Size of the convolution kernel.\n",
    "    n_dilations : int, default 5\n",
    "        Number of dilated convolutions to do. For each convolution, the\n",
    "        dilation rate is 2**idx+1 and the number of filters is 2**idx+4.\n",
    "    list_of_dilation_rates : list of int or None, default None\n",
    "        List of the dilation rates to use in the dilated convolutions. If not\n",
    "        None, the n_dilations is not used and filters must be given with the\n",
    "        same size.\n",
    "    list_of_filters : list of int or None, default None\n",
    "        List of the filter number for each of the dilated convolutions. Must be\n",
    "        of the same size as list_of_dilation_rates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Keras model\n",
    "\n",
    "    \"\"\"\n",
    "    # Shape of the distribution\n",
    "    event_shape = [1]\n",
    "    # Compute how many parameters this distribution requires\n",
    "    params_size = 2\n",
    "    #print(params_size)\n",
    "\n",
    "    \n",
    "    input_sfh = keras.layers.Input(shape=(n_timesteps,1))\n",
    "    input_sed = keras.layers.Input(shape=(n_filters,1))\n",
    "    \n",
    "    # Compress the SED and return some channels\n",
    "    sed_net = tf.keras.Sequential([\n",
    "        tfkl.Input(shape=(125, 1)),\n",
    "        tfkl.Conv1D(16, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(32, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(64, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(64, 3, strides=1, padding='same', activation='relu'),\n",
    "        tfkl.Flatten(),\n",
    "        tfkl.Dense(128, activation='relu'),\n",
    "        tfkl.Dense(8, activation='softplus'),\n",
    "        tfkl.Lambda(lambda x: tf.tile(tf.reshape(x,[-1,1,8]), [1,100,1]))\n",
    "        ])\n",
    "    \n",
    "    merged = keras.layers.Concatenate(axis=-1)([input_sfh, \n",
    "                                                sed_net(input_sed)])\n",
    "    \n",
    "    \n",
    "    # Shift and cut\n",
    "    net = keras.layers.Lambda(\n",
    "            lambda x: tf.pad(x, paddings=tf.constant([[0, 0], [1, 0], [0, 0]]))\n",
    "        )(merged)\n",
    "    \n",
    "    net=keras.layers.Lambda(\n",
    "            lambda x: x[:, :-1, :]\n",
    "        )(net)\n",
    "    \n",
    "\n",
    "    net=keras.layers.Conv1D(\n",
    "            filters=16,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=1,\n",
    "            padding='causal',\n",
    "            activation='relu'\n",
    "        )(net)\n",
    "\n",
    "    if list_of_dilation_rates is None:\n",
    "        list_of_dilation_rates = [2**(i+1) for i in range(n_dilations)]\n",
    "        list_of_filters = [2**(i+4) for i in range(n_dilations)]\n",
    "    elif len(list_of_filters) != len(list_of_dilation_rates):\n",
    "        raise ValueError(\n",
    "            \"filters and list_of_dilation_rates must have the same length\")\n",
    "\n",
    "    for dilation_rate, nb_filters in zip(list_of_dilation_rates,\n",
    "                                         list_of_filters):\n",
    "        net = keras.layers.Conv1D(\n",
    "                filters=nb_filters,\n",
    "                kernel_size=kernel_size,\n",
    "                dilation_rate=dilation_rate,\n",
    "                padding='causal',\n",
    "                activation='relu')(net)\n",
    "    \n",
    "    net = keras.layers.Dense(2)(net)\n",
    "    \n",
    "    net = tfp.layers.DistributionLambda(\n",
    "                    make_distribution_fn=lambda t: tfd.Beta(\n",
    "                          concentration1=tf.math.softplus(t[..., 0])+1e-3,\n",
    "                          concentration0=tf.math.softplus(t[..., 1])+1e-3)\n",
    "                    )(net)\n",
    "    \n",
    "    pixel_cnn = keras.models.Model(inputs=[input_sfh, input_sed],\n",
    "                                  outputs=net)\n",
    "\n",
    "    # Use the negative log-likelihood as loss function.\n",
    "    def negloglik(y, q):\n",
    "        return tf.reduce_sum(-q.log_prob(y[...,0]), -1)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    pixel_cnn.compile(loss=negloglik, optimizer=opt)\n",
    "\n",
    "    return pixel_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d3af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(example):\n",
    "    return tf.reshape(example['SFR_Max'],(-1,100,1)), \\\n",
    "           tf.reshape(example['SFR_Max'],(-1,100,1))\n",
    "\n",
    "def preprocessing_wmass(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    mass_half = example['Mstar_Half'][:,0]\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.add(tf.reshape(example['SFR_Max'],(-1,100,1)), 1e-5)\n",
    "    res = tf.concat([sfr, mass, mass_half], axis=2)\n",
    "    return res, res\n",
    "\n",
    "def preprocessing_wmass_atan(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    #mass_half = example['Mstar_Half'][:,0]\n",
    "    #sed = (tf.gather(example['sed'],inds, axis=1) + 20.70243)/2.0466275\n",
    "    sed = example['sed']\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    #mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.tanh(tf.math.asinh(tf.reshape(example['SFR_Max'],(-1,100,1))/40) + 1e-3 + 0.005*tf.math.softplus(tf.random.normal(shape=[64,100,1])))\n",
    "    res = tf.concat([sfr], axis=2) #  mass, mass_half\n",
    "    return (res, sed), res\n",
    "\n",
    "def input_fn(mode='train', batch_size=64, \n",
    "             dataset_name='tng100', data_dir=None,\n",
    "             include_mass=True, arctan=True):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    keys = ['sed','Mstar', 'SFR_Max', 'mass_quantiles', 'sed', 'time']\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load(dataset_name, split='train[:90%]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys})\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load(dataset_name, split='train[90%:]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys}) #dataset = dataset.repeat()\n",
    "        \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if include_mass and arctan:\n",
    "        dataset = dataset.map(preprocessing_wmass_atan) # Apply data preprocessing\n",
    "    elif include_mass:\n",
    "        dataset = dataset.map(preprocessing_wmass)\n",
    "    else : \n",
    "        dataset = dataset.map(preprocessing)\n",
    "    dataset = dataset.prefetch(-1)       # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e9d8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "dtrain = input_fn(mode='train', batch_size=batch_size, dataset_name='eagle',data_dir=data_dir)\n",
    "#dval = input_fn(mode='val', batch_size=batch_size, dataset_name='eagle',data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20c8393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 7314\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape must be at least rank 2 but is rank 1 [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(dset))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m dset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     sed \u001b[38;5;241m=\u001b[39m (tf\u001b[38;5;241m.\u001b[39mgather(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msed\u001b[39m\u001b[38;5;124m'\u001b[39m],inds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20.70243\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0466275\u001b[39m\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7185\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be at least rank 2 but is rank 1 [Op:GatherV2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 5] Input/output error\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 192, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 563, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1844, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 463, in dispatch_queue\n",
      "    self.log.exception(\"Error in message handler\")\n",
      "Message: 'Error in message handler'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplt as plt\n",
    "print(\"Train\",len(dset))\n",
    "\n",
    "for example in dset.take(1):\n",
    "    sed = (tf.gather(example['sed'],inds, axis=1) + 20.70243)/2.0466275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5569c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 125, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 100, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 100, 8)       152424      ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 100, 9)       0           ['input_4[0][0]',                \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 101, 9)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 100, 9)       0           ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 100, 16)      448         ['lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 100, 16)      784         ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 100, 32)      1568        ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 100, 64)      6208        ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 100, 128)     24704       ['conv1d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 100, 256)     98560       ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 100, 2)       514         ['conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " distribution_lambda_1 (Distrib  ((None, 100),       0           ['dense_5[0][0]']                \n",
      " utionLambda)                    (None, 100))                                                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 285,210\n",
      "Trainable params: 285,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixel_cnn = generate_model(100,125)\n",
    "\n",
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 14ms/step - loss: -229.2484\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -265.5918\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -301.1838\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -313.8039\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -318.1458\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -320.5878\n",
      "Epoch 7/10\n",
      " 280/1000 [=======>......................] - ETA: 10s - loss: -321.4611"
     ]
    }
   ],
   "source": [
    "hist = pixel_cnn.fit(dtrain, \n",
    "                     epochs=epochs,\n",
    "                     steps_per_epoch=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
