{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b865f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "#  Important !!!! path to shared tensorflow dataset\n",
    "data_dir='/storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265a5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfh.datasets.eagle import eagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b650134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version of the requested dataset:\n",
      "2.0.0\n",
      "Using /storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle/eagle/3.0.0 instead.\n",
      "2022-04-12 18:15:36.188107: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle/eagle/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab098661d78479fbee6a0a764e1d169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d154f3b8e64991a19d5ae365f5aee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dc1d8f7dc845778a9e7b8a9070b6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle/eagle/3.0.0.incompleteEJ3MS0/eagle-trai…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset eagle downloaded and prepared to /storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle/eagle/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 18:26:12.497954: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-12 18:26:14.058107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11314 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:02:00.0, compute capability: 6.0\n",
      "2022-04-12 18:26:14.058744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11238 MB memory:  -> device: 1, name: Tesla P100-PCIE-12GB, pci bus id: 0000:83:00.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "dset = tfds.load('eagle', split='train', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d864b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the wavelenghts\n",
    "wl = np.loadtxt('/storage/scratch/mhuertas/data/sfh/tensorflow_datasets/tng100/downloads/manual/wl.csv')\n",
    "inds = argsort(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffcbfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Keras model implementing PixelCNN.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "import time\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfkl=keras.layers\n",
    "\n",
    "def generate_model(n_timesteps, n_filters, *, n_channels=1, n_components=2, kernel_size=3,\n",
    "                   n_dilations=5, list_of_dilation_rates=None,\n",
    "                   list_of_filters=None):\n",
    "    \"\"\"Generate the PixelCNN Keras model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_timesteps : int\n",
    "        Number of time steps.\n",
    "    n_filters : int\n",
    "        Number of filters.\n",
    "    n_channels : int, default 1\n",
    "        Number of channels in the dataset\n",
    "    n_components : int, default 2\n",
    "        Number of components in the Gaussian mixture distribution.\n",
    "    kernel_size : int, default 3\n",
    "        Size of the convolution kernel.\n",
    "    n_dilations : int, default 5\n",
    "        Number of dilated convolutions to do. For each convolution, the\n",
    "        dilation rate is 2**idx+1 and the number of filters is 2**idx+4.\n",
    "    list_of_dilation_rates : list of int or None, default None\n",
    "        List of the dilation rates to use in the dilated convolutions. If not\n",
    "        None, the n_dilations is not used and filters must be given with the\n",
    "        same size.\n",
    "    list_of_filters : list of int or None, default None\n",
    "        List of the filter number for each of the dilated convolutions. Must be\n",
    "        of the same size as list_of_dilation_rates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Keras model\n",
    "\n",
    "    \"\"\"\n",
    "    # Shape of the distribution\n",
    "    event_shape = [1]\n",
    "    # Compute how many parameters this distribution requires\n",
    "    params_size = 2\n",
    "    #print(params_size)\n",
    "\n",
    "    \n",
    "    input_sfh = keras.layers.Input(shape=(n_timesteps,1))\n",
    "    input_sed = keras.layers.Input(shape=(n_filters,1))\n",
    "    \n",
    "    # Compress the SED and return some channels\n",
    "    sed_net = tf.keras.Sequential([\n",
    "        tfkl.Input(shape=(143, 1)),\n",
    "        tfkl.Conv1D(16, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(32, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(64, 3, strides=2, padding='same', activation='relu'),\n",
    "        tfkl.Conv1D(64, 3, strides=1, padding='same', activation='relu'),\n",
    "        tfkl.Flatten(),\n",
    "        tfkl.Dense(128, activation='relu'),\n",
    "        tfkl.Dense(8, activation='softplus'),\n",
    "        tfkl.Lambda(lambda x: tf.tile(tf.reshape(x,[-1,1,8]), [1,280,1]))\n",
    "        ])\n",
    "    \n",
    "    merged = keras.layers.Concatenate(axis=-1)([input_sfh, \n",
    "                                                sed_net(input_sed)])\n",
    "    \n",
    "    \n",
    "    # Shift and cut\n",
    "    net = keras.layers.Lambda(\n",
    "            lambda x: tf.pad(x, paddings=tf.constant([[0, 0], [1, 0], [0, 0]]))\n",
    "        )(merged)\n",
    "    \n",
    "    net=keras.layers.Lambda(\n",
    "            lambda x: x[:, :-1, :]\n",
    "        )(net)\n",
    "    \n",
    "\n",
    "    net=keras.layers.Conv1D(\n",
    "            filters=16,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=1,\n",
    "            padding='causal',\n",
    "            activation='relu'\n",
    "        )(net)\n",
    "\n",
    "    if list_of_dilation_rates is None:\n",
    "        list_of_dilation_rates = [2**(i+1) for i in range(n_dilations)]\n",
    "        list_of_filters = [2**(i+4) for i in range(n_dilations)]\n",
    "    elif len(list_of_filters) != len(list_of_dilation_rates):\n",
    "        raise ValueError(\n",
    "            \"filters and list_of_dilation_rates must have the same length\")\n",
    "\n",
    "    for dilation_rate, nb_filters in zip(list_of_dilation_rates,\n",
    "                                         list_of_filters):\n",
    "        net = keras.layers.Conv1D(\n",
    "                filters=nb_filters,\n",
    "                kernel_size=kernel_size,\n",
    "                dilation_rate=dilation_rate,\n",
    "                padding='causal',\n",
    "                activation='relu')(net)\n",
    "    \n",
    "    net = keras.layers.Dense(2)(net)\n",
    "    \n",
    "    net = tfp.layers.DistributionLambda(\n",
    "                    make_distribution_fn=lambda t: tfd.Beta(\n",
    "                          concentration1=tf.math.softplus(t[..., 0])+1e-3,\n",
    "                          concentration0=tf.math.softplus(t[..., 1])+1e-3)\n",
    "                    )(net)\n",
    "    \n",
    "    pixel_cnn = keras.models.Model(inputs=[input_sfh, input_sed],\n",
    "                                  outputs=net)\n",
    "\n",
    "    # Use the negative log-likelihood as loss function.\n",
    "    def negloglik(y, q):\n",
    "        return tf.reduce_sum(-q.log_prob(y[...,0]), -1)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    pixel_cnn.compile(loss=negloglik, optimizer=opt)\n",
    "\n",
    "    return pixel_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d3af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(example):\n",
    "    return tf.reshape(example['SFR_Max'],(-1,100,1)), \\\n",
    "           tf.reshape(example['SFR_Max'],(-1,100,1))\n",
    "\n",
    "def preprocessing_wmass(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    mass_half = example['Mstar_Half'][:,0]\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.add(tf.reshape(example['SFR_Max'],(-1,100,1)), 1e-5)\n",
    "    res = tf.concat([sfr, mass, mass_half], axis=2)\n",
    "    return res, res\n",
    "\n",
    "def preprocessing_wmass_atan(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    #mass_half = example['Mstar_Half'][:,0]\n",
    "    sed = (tf.gather(example['sed'],inds, axis=1) + 20.70243)/2.0466275\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    #mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.tanh(tf.math.asinh(tf.reshape(example['SFR_Max'],(-1,100,1))/40) + 1e-3 + 0.005*tf.math.softplus(tf.random.normal(shape=[64,100,1])))\n",
    "    res = tf.concat([sfr], axis=2) #  mass, mass_half\n",
    "    return (res, sed), res\n",
    "\n",
    "def input_fn(mode='train', batch_size=64, \n",
    "             dataset_name='tng100', data_dir=None,\n",
    "             include_mass=True, arctan=True):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    keys = ['sed','Mstar', 'SFR_Max', 'mass_quantiles', 'sed', 'time']\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load(dataset_name, split='train[:90%]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys})\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load(dataset_name, split='train[90%:]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys}) #dataset = dataset.repeat()\n",
    "        \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if include_mass and arctan:\n",
    "        dataset = dataset.map(preprocessing_wmass_atan) # Apply data preprocessing\n",
    "    elif include_mass:\n",
    "        dataset = dataset.map(preprocessing_wmass)\n",
    "    else : \n",
    "        dataset = dataset.map(preprocessing)\n",
    "    dataset = dataset.prefetch(-1)       # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9d8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "dtrain = input_fn(mode='train', batch_size=batch_size, dataset_name='eagle',data_dir=data_dir)\n",
    "#dval = input_fn(mode='val', batch_size=batch_size, dataset_name='eagle',data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5569c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 143, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 143, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 125, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 143, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 143, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 125, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 1152, but received input with shape (None, 1024)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 125, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pixel_cnn \u001b[38;5;241m=\u001b[39m generate_model(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m125\u001b[39m)\n\u001b[1;32m      3\u001b[0m pixel_cnn\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mgenerate_model\u001b[0;34m(n_timesteps, n_filters, n_channels, n_components, kernel_size, n_dilations, list_of_dilation_rates, list_of_filters)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Compress the SED and return some channels\u001b[39;00m\n\u001b[1;32m     57\u001b[0m sed_net \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     58\u001b[0m     tfkl\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m143\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m     59\u001b[0m     tfkl\u001b[38;5;241m.\u001b[39mConv1D(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     tfkl\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mtile(tf\u001b[38;5;241m.\u001b[39mreshape(x,[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m]), [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m280\u001b[39m,\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     67\u001b[0m     ])\n\u001b[1;32m     69\u001b[0m merged \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)([input_sfh, \n\u001b[0;32m---> 70\u001b[0m                                             \u001b[43msed_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sed\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Shift and cut\u001b[39;00m\n\u001b[1;32m     74\u001b[0m net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mpad(x, paddings\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m     76\u001b[0m     )(merged)\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/input_spec.py:248\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    246\u001b[0m       value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {value, \u001b[38;5;28;01mNone\u001b[39;00m}:\n\u001b[0;32m--> 248\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    249\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    250\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut received input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 1152, but received input with shape (None, 1024)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 125, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "pixel_cnn = generate_model(100,125)\n",
    "\n",
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c0fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "2022-04-12 12:48:16.115534: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28796/1104545249.py\", line 1, in <cell line: 1>\n      hist = pixel_cnn.fit(dtrain,\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/layers/core/flatten.py\", line 96, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'model/sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 12288 values, but the requested shape requires a multiple of 1152\n\t [[{{node model/sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_5044]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m pixel_cnn\u001b[38;5;241m.\u001b[39mfit(dtrain, \n\u001b[1;32m      2\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39mepochs, \n\u001b[1;32m      3\u001b[0m                      steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/python/python3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28796/1104545249.py\", line 1, in <cell line: 1>\n      hist = pixel_cnn.fit(dtrain,\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/python/python3.8/lib/python3.8/site-packages/keras/layers/core/flatten.py\", line 96, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'model/sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 12288 values, but the requested shape requires a multiple of 1152\n\t [[{{node model/sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_5044]"
     ]
    }
   ],
   "source": [
    "hist = pixel_cnn.fit(dtrain, \n",
    "                     epochs=epochs, \n",
    "                     steps_per_epoch=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
