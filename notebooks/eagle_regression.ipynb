{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "import time\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfkl=keras.layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#path to shared tensorflow dataset\n",
    "eagle_dir='/storage/scratch/mhuertas/data/sfh/tensorflow_datasets/eagle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfh.datasets.eagle import eagle\n",
    "\n",
    "dset_eagle = tfds.load('eagle', split='train', data_dir=eagle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\",len(dset_eagle))\n",
    "\n",
    "for example in dset_eagle.take(3):\n",
    "    print(example)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "for example in dset_eagle.take(3):\n",
    "    #print(wl[example['inds_valid']])\n",
    "    axs.plot(example['time'],example['SFR_Max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing, include normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(example):\n",
    "    return tf.reshape(example['SFR_Max'],(-1,100,1)), \\\n",
    "           tf.reshape(example['SFR_Max'],(-1,100,1))\n",
    "\n",
    "def preprocessing_wmass(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    mass_half = example['Mstar_Half'][:,0]\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.add(tf.reshape(example['SFR_Max'],(-1,100,1)), 1e-5)\n",
    "    res = tf.concat([sfr, mass, mass_half], axis=2)\n",
    "    return res, res\n",
    "\n",
    "def preprocessing_wmass_atan(example):\n",
    "    mass = example['Mstar'][:,0]\n",
    "    #mass_half = example['Mstar_Half'][:,0]\n",
    "    #sed = (tf.gather(example['sed'],inds, axis=1) + 20.70243)/2.0466275\n",
    "    sed = example['sed']\n",
    "    tiler = tf.constant([100])\n",
    "    mass = tf.reshape(tf.tile(mass, tiler),(-1,100,1))\n",
    "    #mass_half = tf.reshape(tf.tile(mass_half, tiler),(-1,100,1))\n",
    "    sfr = tf.math.tanh(tf.math.asinh(tf.reshape(example['SFR_Max'],(-1,100,1))/40) + 1e-3 + 0.005*tf.math.softplus(tf.random.normal(shape=[64,100,1])))\n",
    "    res = tf.concat([sfr], axis=2) #  mass, mass_half\n",
    "    return (res, sed), res\n",
    "\n",
    "def input_fn(mode='train', batch_size=64, \n",
    "             dataset_name='tng100', data_dir=None,\n",
    "             include_mass=True, arctan=True):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    keys = ['sed','Mstar', 'SFR_Max', 'mass_quantiles', 'sed', 'time']\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load(dataset_name, split='train[:90%]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys})\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load(dataset_name, split='train[90%:]', data_dir=data_dir)\n",
    "        dataset = dataset.map(lambda x: {k:x[k] for k in keys}) #dataset = dataset.repeat()\n",
    "        \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if include_mass and arctan:\n",
    "        dataset = dataset.map(preprocessing_wmass_atan) # Apply data preprocessing\n",
    "    elif include_mass:\n",
    "        dataset = dataset.map(preprocessing_wmass)\n",
    "    else : \n",
    "        dataset = dataset.map(preprocessing)\n",
    "    dataset = dataset.prefetch(-1)       # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare your training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "dtrain_eagle = input_fn(mode='train', batch_size=batch_size, dataset_name='eagle',data_dir=eagle_dir)\n",
    "dval_eagle = input_fn(mode='val', batch_size=batch_size, dataset_name='eagle',data_dir=eagle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating regression model (CNN with continuous output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Keras model implementing PixelCNN.\"\"\"\n",
    "\n",
    "\n",
    "def generate_model():\n",
    "    \"\"\"Generate the regression Keras model.\n",
    "\n",
    "    Parameters\"\"\"\n",
    "    ----------\n",
    "\n",
    "    return regression_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_cnn = generate_model()\n",
    "regression_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit your model with EAGLE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = regression_cnn.fit(dtrain_eagle, \n",
    "                     epochs=epochs,\n",
    "                     steps_per_epoch=1000,validation_data=dval_eagle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with EAGLE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_test = dval_eagle.as_numpy_iterator()\n",
    "data = next(dset_test)\n",
    "ind=55\n",
    "sample = np.zeros([64,100,1])\n",
    "true = data[0][0][ind,:,0]\n",
    "sed = data[0][1][ind].reshape([1,125,1]).repeat(64,axis=0)\n",
    "\n",
    "# init at the \n",
    "sample[:,0,0] = true[0]\n",
    "\n",
    "for i in range(99):\n",
    "    tmp = eagle_cnn((sample, sed)).sample()\n",
    "    sample[:,i+1,0] = tmp[:,i+1]\n",
    "\n",
    "plt.plot(true,label='true SFH')\n",
    "for i in range(64):\n",
    "    plt.plot(sample[i,:,0],color='C1',alpha=0.1)\n",
    "plt.plot(sample[1,:,0],color='C1',alpha=1.,label='individual sample')    \n",
    "plt.plot(sample.mean(axis=0)[:,0],'--',color='red',label='mean posterior')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
